{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LINEAR REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array([11,23,44,66])\n",
    "w=np.array([13,12,14,15])\n",
    "b=23\n",
    "\n",
    "def pre_dic(x,w,b):\n",
    "    n=x.shape[0]\n",
    "    p=0\n",
    "    for i in range(n):\n",
    "        p_i=x[i]*w[i]\n",
    "        p=p+p_i\n",
    "    p=p+b\n",
    "    return p\n",
    "\n",
    "print(pre_dic(x,w,b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_dict(x,w,b):\n",
    "      p=np.dot(x,w)+b\n",
    "      return p\n",
    "    \n",
    "print(pre_dict(x,w,b)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array([[34,56,23,98],\n",
    "            [43,62,43,77],\n",
    "            [12,77,84,23]])\n",
    "w=np.array([1.1,2.2,3.3,4.4])\n",
    "y=np.array([100,200,300,400])\n",
    "b=0.55\n",
    "\n",
    "def cost_fun(x,y,w,b):\n",
    "    n=x.shape[0]\n",
    "    cost=0.0  \n",
    "    for i in range(n):\n",
    "        f_wb=np.dot(x[i],w)+b\n",
    "        cost=cost+(f_wb-y[i])**2\n",
    "    cost=1/(2*n)*cost\n",
    "    return cost\n",
    "    \n",
    "result=cost_fun(x,y,w,b)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array([[34,56,23,98],\n",
    "            [43,62,43,77],\n",
    "            [12,77,84,23]])\n",
    "w=np.array([1.1,2.2,3.3,4.4])\n",
    "y=np.array([100,200,300,400])\n",
    "b=0.55\n",
    "\n",
    "\n",
    "def deriv_respw(x,y,w,b):\n",
    "    m,n=x.shape\n",
    "    d_dw=np.zeros(n)\n",
    "    d_db=0.\n",
    "    for i in range(m):\n",
    "        err=(np.dot(x[i],w)+b)-y[i]\n",
    "        for j in range(n):\n",
    "            d_dw[j]=d_dw[j]+err*x[i,j]\n",
    "        d_db=d_db+err\n",
    "        \n",
    "    d_dw=1/m*d_dw\n",
    "    d_db=1/m*d_db\n",
    "    return d_dw,d_db\n",
    "\n",
    "result=deriv_respw(x,y,w,b)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array([[34,56,23,98],\n",
    "            [43,62,43,77],\n",
    "            [12,77,84,23]])\n",
    "w=np.array([1.1,2.2,3.3,4.4])\n",
    "y=np.array([100,200,300,400])\n",
    "b=0.55\n",
    "num_iters=1000\n",
    "\n",
    "\n",
    "def gradient_descent(x,y,w,b,cost_fun,alpha,num_iters,deriv_respw):\n",
    "    j_history=[]\n",
    "    w=copy.deepcopy(w_init)\n",
    "    b=b_init\n",
    "    for i in range(num_iters):\n",
    "        d_dw,d_db=deriv_respw(x,y,w,b)\n",
    "        w=w-alpha*d_dw\n",
    "        b=b-alpha*d_db\n",
    "        if i < 10000:\n",
    "            j_history.append(cost_fun(x,y,w,b))\n",
    "        if i% math.ceil(num_iters / 10) == 0:\n",
    "            print(f\"Iteration {i:4d}: Cost {J_history[-1]:8.2f}   \")\n",
    "    return w,b,j_history\n",
    "\n",
    "result=gradient_descent(x,y,w,b,cost_fun,alpha,num_iters,deriv_respw)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression cost with regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_reg_coreg(x,y,w,b,lamba_=1):\n",
    "    m=x.shape[0]\n",
    "    n=len(w)\n",
    "    cost=0.\n",
    "    for i in range(m):\n",
    "        f_wb=np.dot(w,x[i])+b\n",
    "        cost=cost+(f_wb-y[i])**2\n",
    "    cost=1/(2*m)*cost\n",
    "    \n",
    "    reg_cost=0\n",
    "    for j in range(n):\n",
    "        reg_cost=reg_cost+(w[j]**2)\n",
    "    reg_cost=(lambda_/(2*m))*reg_cost\n",
    "    \n",
    "    total_cost=cost+reg_cost\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient function for regularized linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_reg_lin(x,y,w,b,lambda_):\n",
    "    m,n=x.shape\n",
    "    d_dw=np.zeros(n,)\n",
    "    d_db=0.\n",
    "    \n",
    "    for i in range(m):\n",
    "        err=np.dot(w,x[i])+b-y[i]\n",
    "        for j in range(n):\n",
    "            d_dw[j]=d_dw[j]+err*x[i,j]\n",
    "        d_db=d_db+err\n",
    "        \n",
    "    d_dw=1/m*d_dw\n",
    "    d_db=1/m*d_db\n",
    "    \n",
    "    for j in range(n):\n",
    "        d_dw[j]=d_dw[j]+(lambda_/m)*w[j]\n",
    "        \n",
    "    return d_dw,d_db "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
